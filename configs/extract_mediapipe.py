"""Configuration for MediaPipe landmark extraction (scripts/3a_extract_mediapipe.py)"""
import os

# =============================================================================
# PROJECT PATHS
# =============================================================================

# Base paths
ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
VIDEO_DIR = os.path.join(ROOT, "dataset", "origin")
NPY_DIR = os.path.join(ROOT, "dataset", "npy")

# Manifest CSV file (contains video segment timestamps and metadata)
# For YouTube-ASL: use assets/youtube_asl.csv (generated by step 2)
# For How2Sign: use dataset/how2sign/how2sign_realigned_val.csv
CSV_FILE = os.path.join(ROOT, "dataset", "how2sign", "how2sign_realigned_val.csv")

# =============================================================================
# FRAME SAMPLING CONFIGURATION
# =============================================================================

# Option to downsample frames to a fixed FPS (takes priority over FRAME_SKIP)
# Note: Only downsamples, does not upsample (if source fps < REDUCE_FPS_TO, keeps every frame)
REDUCE_FPS_TO = 24.0  # Target FPS (set to None to disable FPS reduction)

# Frame sampling when NOT using REDUCE_FPS_TO (sample every Nth frame)
FRAME_SKIP = 2  # e.g., 2 means sampling rate is 1/2 (every other frame)

# Accepted video FPS range (videos outside this range will be skipped)
# This helps filter out unusual videos with very low or very high frame rates
ACCEPT_VIDEO_FPS_WITHIN = (24.0, 60.0)  # (min_fps, max_fps)

# =============================================================================
# PROCESSING CONFIGURATION
# =============================================================================

# Maximum number of worker processes for parallel video processing
# Adjust based on available CPU cores and memory
MAX_WORKERS = 4

# =============================================================================
# KEYPOINT REDUCTION CONFIGURATION
# =============================================================================

# Whether to apply keypoint reduction during extraction (Step 3)
# True:  Reduce to 85 selected keypoints (6 pose + 41 face + 42 hands)
#        Output shape: (T, 85, 4) with [x, y, z, visibility]
# False: Keep all MediaPipe Holistic landmarks (532 total keypoints)
#        Output shape: (T, 532, 4) with [x, y, z, visibility]
#        Keypoint reduction deferred to Step 4
REDUCTION = True

# =============================================================================
# MEDIAPIPE LANDMARK INDICES (BlazePose Format)
# Only used when REDUCTION=True
# =============================================================================

# Hand landmarks: All 21 keypoints per hand (wrist, palm, fingers)
HAND_IDX = list(range(21))
POSE_IDX = [11, 12, 13, 14, 23, 24]
FACE_IDX = [
    # Face contour and key points
    0, 4, 13, 14, 17, 33, 37, 39, 46, 52, 55, 61, 64, 81, 82, 93,
    # Additional facial features
    133, 151, 152, 159, 172, 178, 181, 263, 269, 276, 282, 285, 291,
    294, 311, 323, 362, 386, 397, 468, 473
]

# Total output dimensions per frame (when REDUCTION=True):
# = 6 pose + 41 face + 21 left_hand + 21 right_hand = 85 keypoints
# = 85 keypoints × [x, y, z, visibility] = 340 features
# Note: Visibility channel removal (85 × 3 = 255) happens in Step 4 after normalization
#
# When REDUCTION=False: 532 keypoints × 4 = 2128 features
# MediaPipe Holistic provides: 33 pose + 468 face + 21 left_hand + 21 right_hand = 543 total
# (Note: Actual count may vary based on MediaPipe version)
